{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/neven-x/Social-Hierarchy-RL/blob/main/RL_Social_Hierarchy_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "jmu7fw-JNem8",
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-07-21T09:23:03.789324Z",
     "end_time": "2023-07-21T09:23:03.804438Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import functools\n",
    "import random\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv3D\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from pettingzoo.utils.env import ParallelEnv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jq_Xm1J6ysY8",
    "outputId": "216e14d0-540a-48a8-86ee-f7ecd0cd7efc",
    "ExecuteTime": {
     "start_time": "2023-07-21T09:33:49.280092Z",
     "end_time": "2023-07-21T09:33:49.297123Z"
    }
   },
   "outputs": [],
   "source": [
    "class Hierarchy_Grid(ParallelEnv):\n",
    "    metadata = {\n",
    "        \"name\": \"Hierarchy Grid\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, grid_size, num_agents, max_iter):\n",
    "        self.timestep = None\n",
    "        self.grid_size = grid_size\n",
    "        self.agents = np.arange(num_agents)\n",
    "        self.max_iter = max_iter\n",
    "        self.agent_positions = None\n",
    "        self.food_positions = None\n",
    "        self.fight_probs = {name: np.zeros(self.num_agents) for name in self.agents}\n",
    "        self.rewards = {name: 0 for name in self.agents}\n",
    "\n",
    "        self.observation_space = spaces.MultiDiscrete([self.grid_size, self.grid_size, self.num_agents + 1])\n",
    "        self.action_space = spaces.Discrete(5)\n",
    "\n",
    "        self.food_position_map = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.agent_position_maps = {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.timestep = 0\n",
    "\n",
    "        self.agent_positions = {}\n",
    "        self.agent_position_maps = {}\n",
    "        for agent in self.agents:\n",
    "\n",
    "            agent_position = np.random.randint(0, self.grid_size, 2)\n",
    "            self.agent_positions[agent] = agent_position\n",
    "\n",
    "            agent_position_map = np.zeros((self.grid_size, self.grid_size))\n",
    "            agent_position_map[agent_position] = 1\n",
    "            self.agent_position_maps[agent] = agent_position_map\n",
    "\n",
    "        self.food_positions = [np.random.randint(0, self.grid_size, 2)]\n",
    "        self.food_position_map = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.food_position_map[self.food_positions[0]] = 1\n",
    "\n",
    "        observations = np.stack(self.agent_position_maps.values())\n",
    "        observations = np.concatenate([observations, np.expand_dims(self.food_position_map, axis=-1)], axis=-1)\n",
    "\n",
    "        observations = {name: observations for name in self.agents}\n",
    "        return observations, {}\n",
    "\n",
    "    def step(self, actions):\n",
    "\n",
    "        self.timestep += 1\n",
    "\n",
    "        for agent in self.agents:\n",
    "            action = actions[agent]\n",
    "            self.move_agent(agent, action)\n",
    "\n",
    "        self.several_on_food_tile()\n",
    "\n",
    "        if self.timestep > self.max_iter:\n",
    "            terminations = {name: True for name in self.agents}\n",
    "        else:\n",
    "            terminations = {name: False for name in self.agents}\n",
    "\n",
    "        # Add check if any agents have 0 food in which case they die\n",
    "\n",
    "        observations = np.stack(self.agent_position_maps.values())\n",
    "        observations = np.concatenate([observations, np.expand_dims(self.food_position_map, axis=-1)], axis=-1)\n",
    "\n",
    "        observations = {name: observations for name in self.agents}\n",
    "\n",
    "        return observations, self.rewards, terminations, _, {}\n",
    "\n",
    "\n",
    "    def move_agent(self, agent, action):\n",
    "        # Move the agent based on the selected action\n",
    "        x, y = self.agent_positions[agent]\n",
    "\n",
    "        if action == 0:  # Up\n",
    "            x -= 1\n",
    "        elif action == 1:  # Down\n",
    "            x += 1\n",
    "        elif action == 2:  # Left\n",
    "            y -= 1\n",
    "        elif action == 3:  # Right\n",
    "            y += 1\n",
    "        elif action == 4:  # Stay\n",
    "            pass\n",
    "\n",
    "        # Check if the new position is within grid boundaries\n",
    "        if 0 <= x < self.grid_size and 0 <= y < self.grid_size:\n",
    "            self.agent_positions[agent] = (x, y)\n",
    "\n",
    "\n",
    "    def conflict(self, agent1, agent2):\n",
    "\n",
    "        def sig(x):\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        # Agents make decision to fight or leave\n",
    "        # 1 == fight, 0 == leave\n",
    "        decision1 = bool(np.random.binomial(1, sig(self.fight_probs[agent1][agent2])))\n",
    "        decision2 = bool(np.random.binomial(1, sig(self.fight_probs[agent2][agent1])))\n",
    "\n",
    "\n",
    "        # Outcome of fight is determined in case both decide to stay\n",
    "        outcome = np.random.binomial(1, 0.5)\n",
    "        if outcome == 0:\n",
    "            outcome = -1\n",
    "\n",
    "        if not (decision1):\n",
    "            self.relocate_agent(agent1)\n",
    "        if not (decision2):\n",
    "            self.relocate_agent(agent2)\n",
    "\n",
    "        reward_dict = {(False, False): (0, 0),\n",
    "                       (True, False): (5, 0),\n",
    "                       (False, True): (0, 5),\n",
    "                       (True, True): (5 * outcome, 5 * np.delete([-1,1], outcome))}\n",
    "\n",
    "        # Allocate rewards based on decisions and fight outcome\n",
    "        reward1, reward2 = reward_dict((decision1, decision2))\n",
    "        self.reward[agent1] += reward1\n",
    "        self.reward[agent2] += reward2\n",
    "\n",
    "        # Update future staying probabilities\n",
    "        lr = 0.01\n",
    "        self.stay_prob[agent1][agent2] += lr * reward1 * (decision1 - sig(self.stay_prob[agent1][agent2]))\n",
    "        self.stay_prob[agent2][agent1] += lr * reward2 * (decision2 - sig(self.stay_prob[agent2][agent1]))\n",
    "\n",
    "    def several_on_food_tile(self):\n",
    "\n",
    "        for food_tile in self.food_positions:\n",
    "            agents_on_tile = [agent for agent, position in self.agent_positions.items() if (position == food_tile).all()]\n",
    "\n",
    "        if len(agents_on_tile) > 1:\n",
    "\n",
    "            pairs = zip(agents_on_tile[:-1], agents_on_tile[1:])\n",
    "\n",
    "            for pair in pairs:\n",
    "                \n",
    "                self.conflict(pair[0], pair[1])\n",
    "\n",
    "\n",
    "    def relocate_agent(self, agent):\n",
    "        # Relocate the agent to an adjacent position\n",
    "        agent_position = self.agent_positions[agent]\n",
    "\n",
    "        valid_position = False\n",
    "        step = 1\n",
    "        while not valid_position:\n",
    "\n",
    "            # Generate moves\n",
    "            possible_moves = np.array([[0, 1], [0, -1], [1, 0], [-1, 0]]) * step  # Right, Left, Down, Up\n",
    "\n",
    "            # Check if any of new positions are valid (within gridworld and not already occupied)\n",
    "            for move in possible_moves:\n",
    "                new_position = tuple(map(sum, zip(agent_position, move)))\n",
    "\n",
    "                if 0 <= new_position[0] < self.grid_size and 0 <= new_position[1] < self.grid_size:\n",
    "                    if np.isin((1,2), list(env.agent_positions.values())).any():\n",
    "\n",
    "                        valid_position = True\n",
    "                        self.agent_positions[agent] = new_position\n",
    "                        agent_position_map = np.zeros((self.grid_size, self.grid_size))\n",
    "                        agent_position_map[new_position] = 1\n",
    "                        self.agent_position_maps[agent] = agent_position_map\n",
    "\n",
    "            step += 1\n",
    "\n",
    "    def render(self):\n",
    "\n",
    "        fig = plt.figure(figsize=(5,5), frameon=False)\n",
    "\n",
    "        plt.title(\"Grid World\",size=13)\n",
    "        plt.xticks(np.arange(0,self.grid_size,1))\n",
    "        plt.yticks(np.arange(0,self.grid_size,1))\n",
    "\n",
    "        agent_position_map = sum(self.agent_position_maps.values())\n",
    "\n",
    "        plt.imshow(self.food_position_map, vmax = 2, cmap = 'Greens', alpha=0.4, extent=[0, 10, 0, 10])\n",
    "        plt.imshow(agent_position_map, vmax = 2, cmap = 'Reds', alpha=0.4, extent=[0, 10, 0, 10])\n",
    "\n",
    "        ax = plt.gca();\n",
    "        ax.grid()\n",
    "\n",
    "        plt.show()\n",
    "        plt.figure()\n",
    "\n",
    "gym.register(\n",
    "    id='Hierarchy_Grid',\n",
    "    entry_point=Hierarchy_Grid,\n",
    "    kwargs={'grid_size': 10, 'num_agents': 10, 'max_iter': 200}\n",
    ")\n",
    "\n",
    "env = gym.make('Hierarchy_Grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_shape, action_size):\n",
    "        self.state_shape = state_shape\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95  # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=self.state_shape))\n",
    "        model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):  # action selection, epsilon-greedy.\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def update(self, state, action, reward, next_state):\n",
    "        target = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "        target_f = self.model.predict(state)\n",
    "        target_f[0][action] = target\n",
    "        self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma * np.amax(self.model.predict(next_state)[0]))\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-21T09:22:23.874435Z",
     "end_time": "2023-07-21T09:22:23.875658Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "AI6-NSubtqn5",
    "ExecuteTime": {
     "start_time": "2023-07-21T09:33:56.636123Z",
     "end_time": "2023-07-21T09:33:57.017439Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Hierarchy_Grid')\n",
    "n_actions = env.action_space.n\n",
    "state_shape = env.observation_space\n",
    "\n",
    "Np = 10\n",
    "players = []\n",
    "for i in range(Np):\n",
    "    players.append(DQNAgent((10, 10, 11), n_actions))\n",
    "\n",
    "# initial state, maybe we don't want to reset the fight probs\n",
    "Neps = 1000\n",
    "\n",
    "# ---- model training/visualization loop\n",
    "for eps in range(Neps):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = []\n",
    "        # get actions of all agents\n",
    "        #env.render()\n",
    "        for p in range(Np):\n",
    "            action.append(players[p].act(state))\n",
    "        next_state, reward, terminations, _, _ = env.step(action)  # we need reward to be a list of size Np\n",
    "        done = np.all(terminations.values())\n",
    "\n",
    "        '''for agent in range(Np):  # the DQN should also be updated in each step\n",
    "            players[p].remember(state[agent], action[agent], reward[agent], next_state, done)'''\n",
    "\n",
    "        if not done:\n",
    "            for p in range(Np):\n",
    "                # train the model in each step\n",
    "                players[p].update(state, action[p], reward[p], next_state)\n",
    "                state = next_state\n",
    "\n",
    "    # train the model by replay, leverages memory\n",
    "    '''batch_size = 32  # try a larger batch size for better stability and efficiency\n",
    "    for p in range(Np):\n",
    "        players[p].replay(batch_size)'''\n",
    "\n",
    "state = env.reset()  # Reset the environment at the start of each episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/borakn/opt/anaconda3/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:272: UserWarning: \u001B[33mWARN: No render modes was declared in the environment (env.metadata['render_modes'] is None or not defined), you may have trouble when calling `.render()`.\u001B[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 500x500 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-21T09:34:24.461069Z",
     "end_time": "2023-07-21T09:34:24.575827Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "({0: array([[[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.]],\n  \n         ...,\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[1., 1., 1., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.]]]),\n  1: array([[[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.]],\n  \n         ...,\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[1., 1., 1., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.]]]),\n  2: array([[[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.]],\n  \n         ...,\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[1., 1., 1., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.]]]),\n  3: array([[[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.]],\n  \n         ...,\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[1., 1., 1., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.]]]),\n  4: array([[[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.]],\n  \n         ...,\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[1., 1., 1., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.]]]),\n  5: array([[[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.]],\n  \n         ...,\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[1., 1., 1., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.]]]),\n  6: array([[[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.]],\n  \n         ...,\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[1., 1., 1., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.]]]),\n  7: array([[[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.]],\n  \n         ...,\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[1., 1., 1., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.]]]),\n  8: array([[[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.]],\n  \n         ...,\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[1., 1., 1., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.]]]),\n  9: array([[[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.]],\n  \n         ...,\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.]],\n  \n         [[1., 1., 1., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.],\n          [0., 0., 0., ..., 0., 0., 1.]],\n  \n         [[0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0., ..., 0., 0., 0.],\n          [0., 0., 0., ..., 0., 0., 0.],\n          [1., 1., 1., ..., 1., 1., 0.]]])},\n {})"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('Hierarchy_Grid')\n",
    "\n",
    "env.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-20T11:16:48.893546Z",
     "end_time": "2023-07-20T11:16:48.918201Z"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
