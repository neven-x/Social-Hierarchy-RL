{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/neven-x/Social-Hierarchy-RL/blob/main/RL_Social_Hierarchy_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "id": "jmu7fw-JNem8",
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-07-21T11:43:00.008810Z",
     "end_time": "2023-07-21T11:43:05.371853Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import functools\n",
    "import random\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import torch\n",
    "\n",
    "from pettingzoo.utils.env import ParallelEnv\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "outputs": [],
   "source": [
    "def set_device():\n",
    "    \"\"\"\n",
    "    Set the device. CUDA if available, CPU otherwise\n",
    "\n",
    "    Args:\n",
    "      None\n",
    "\n",
    "    Returns:\n",
    "      Nothing\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    if device != \"cuda\":\n",
    "        print(\"WARNING: For this notebook to perform best, \"\n",
    "              \"if possible, in the menu under `Runtime` -> \"\n",
    "              \"`Change runtime type.`  select `GPU` \")\n",
    "    else:\n",
    "        print(\"GPU is enabled in this notebook.\")\n",
    "\n",
    "    return device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-21T11:43:06.686164Z",
     "end_time": "2023-07-21T11:43:06.690550Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jq_Xm1J6ysY8",
    "outputId": "216e14d0-540a-48a8-86ee-f7ecd0cd7efc",
    "ExecuteTime": {
     "start_time": "2023-07-21T17:31:33.718342Z",
     "end_time": "2023-07-21T17:31:33.719607Z"
    }
   },
   "outputs": [],
   "source": [
    "class Hierarchy_Grid(ParallelEnv):\n",
    "    metadata = {\n",
    "        \"name\": \"Hierarchy Grid\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, grid_size, num_agents, max_iter):\n",
    "        self.timestep = None\n",
    "        self.grid_size = grid_size\n",
    "        self.possible_agents = np.arange(num_agents)\n",
    "        self.agents = np.arange(num_agents)\n",
    "        self.max_iter = max_iter\n",
    "        self.agent_positions = None\n",
    "        self.food_positions = None\n",
    "        self.fight_probs = {name: np.zeros(self.num_agents) for name in self.agents}\n",
    "        self.rewards = {name: 0 for name in self.agents}\n",
    "\n",
    "        self.observation_space = spaces.MultiDiscrete([self.grid_size, self.grid_size, self.num_agents + 1])\n",
    "        self.action_space = spaces.Discrete(5)\n",
    "\n",
    "        self.food_positions = []\n",
    "        self.food_position_map = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.agent_position_maps = {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.timestep = 0\n",
    "\n",
    "        self.agent_positions = {}\n",
    "        self.agent_position_maps = {}\n",
    "        for agent in self.agents:\n",
    "\n",
    "            agent_position = np.random.randint(0, self.grid_size, 2)\n",
    "            self.agent_positions[agent] = agent_position\n",
    "\n",
    "            agent_position_map = np.zeros((self.grid_size, self.grid_size))\n",
    "            agent_position_map[agent_position[0], agent_position[1]] = 1\n",
    "            self.agent_position_maps[agent] = agent_position_map\n",
    "\n",
    "        self.food_positions = []\n",
    "        self.food_position_map = np.zeros((self.grid_size, self.grid_size))\n",
    "        for n in range(5):\n",
    "            self.generate_food()\n",
    "\n",
    "        observations = np.stack(self.agent_position_maps.values())\n",
    "        observations = np.concatenate([observations, np.expand_dims(self.food_position_map, axis=-1)], axis=-1)\n",
    "        observations = np.expand_dims(observations, axis=0)\n",
    "\n",
    "        observations = {name: observations for name in self.agents}\n",
    "        return observations, {}\n",
    "\n",
    "    def step(self, actions):\n",
    "\n",
    "        self.timestep += 1\n",
    "        self.rewards = {name: 0 for name in self.agents}\n",
    "\n",
    "        for agent in self.agents:\n",
    "            action = actions[agent]\n",
    "            self.move_agent(agent, action)\n",
    "\n",
    "        self.several_on_food_tile()\n",
    "        self.depl_food()\n",
    "\n",
    "        if bool(np.random.binomial(1, 1/50)):\n",
    "            self.generate_food()\n",
    "\n",
    "\n",
    "        if self.timestep > self.max_iter:\n",
    "            terminations = {name: True for name in self.agents}\n",
    "        else:\n",
    "            terminations = {name: False for name in self.agents}\n",
    "\n",
    "        observations = np.stack(self.agent_position_maps.values())\n",
    "        observations = np.concatenate([observations, np.expand_dims(self.food_position_map, axis=-1)], axis=-1)\n",
    "        observations = np.expand_dims(observations, axis=0)\n",
    "\n",
    "        observations = {name: observations for name in self.agents}\n",
    "\n",
    "        return observations, self.rewards, terminations, _, {}\n",
    "\n",
    "    def generate_food(self):\n",
    "        new_tile = np.random.randint(0, self.grid_size, 2)\n",
    "        self.food_positions.append(new_tile)\n",
    "        self.food_position_map[new_tile[0], new_tile[1]] += 1\n",
    "\n",
    "    def depl_food(self):\n",
    "        for agent in self.agents:\n",
    "            agent_position = self.agent_positions[agent]\n",
    "            if self.food_position_map[agent_position[0], agent_position[1]] > 0:\n",
    "                self.food_position_map[agent_position[0], agent_position[1]] -= 1/5\n",
    "\n",
    "                if self.food_position_map[agent_position[0], agent_position[1]] <= 0:\n",
    "                    self.food_positions = [tile for tile in self.food_positions if not np.array_equal(tile, agent_position)]\n",
    "\n",
    "    def move_agent(self, agent, action):\n",
    "        # Move the agent based on the selected action\n",
    "        x, y = self.agent_positions[agent]\n",
    "\n",
    "        if action == 0:  # Up\n",
    "            x -= 1\n",
    "        elif action == 1:  # Down\n",
    "            x += 1\n",
    "        elif action == 2:  # Left\n",
    "            y -= 1\n",
    "        elif action == 3:  # Right\n",
    "            y += 1\n",
    "        elif action == 4:  # Stay\n",
    "            pass\n",
    "\n",
    "        # Check if the new position is within grid boundaries\n",
    "        if 0 <= x < self.grid_size and 0 <= y < self.grid_size:\n",
    "            self.agent_positions[agent] = (x, y)\n",
    "\n",
    "            new_map = np.zeros((self.grid_size, self.grid_size))\n",
    "            new_map[x, y] = 1\n",
    "            self.agent_position_maps[agent] = new_map\n",
    "\n",
    "\n",
    "    def conflict(self, agent1, agent2):\n",
    "\n",
    "        print(f\"Conflict happened between agents {agent1}, {agent2}\")\n",
    "\n",
    "        def sig(x):\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        # Agents make decision to fight or leave\n",
    "        # 1 == fight, 0 == leave\n",
    "        decision1 = bool(np.random.binomial(1, sig(self.fight_probs[agent1][agent2])))\n",
    "        decision2 = bool(np.random.binomial(1, sig(self.fight_probs[agent2][agent1])))\n",
    "\n",
    "        # Outcome of fight is determined in case both decide to stay\n",
    "        outcome = np.random.binomial(1, 0.5)\n",
    "        if outcome == 0:\n",
    "            outcome = -1\n",
    "\n",
    "        if not (decision1):\n",
    "            self.relocate_agent(agent1)\n",
    "        if not (decision2):\n",
    "            self.relocate_agent(agent2)\n",
    "\n",
    "        reward_dict = {(False, False): (0, 0),\n",
    "                       (True, False): (5, 0),\n",
    "                       (False, True): (0, 5),\n",
    "                       (True, True): (5 * outcome, 5 * np.delete([-1,1], outcome))}\n",
    "\n",
    "        # Allocate rewards based on decisions and fight outcome\n",
    "        reward1, reward2 = reward_dict[(decision1, decision2)]\n",
    "        self.rewards[agent1] += reward1\n",
    "        self.rewards[agent2] += reward2\n",
    "\n",
    "        # Update future staying probabilities\n",
    "        lr = 0.01\n",
    "        self.fight_probs[agent1][agent2] += lr * reward1 * (decision1 - sig(self.fight_probs[agent1][agent2]))\n",
    "        self.fight_probs[agent2][agent1] += lr * reward2 * (decision2 - sig(self.fight_probs[agent2][agent1]))\n",
    "\n",
    "    def several_on_food_tile(self):\n",
    "\n",
    "        for food_tile in self.food_positions:\n",
    "            agents_on_tile = [agent for agent, position in self.agent_positions.items() if (position == food_tile).all()]\n",
    "\n",
    "        if len(agents_on_tile) > 1:\n",
    "\n",
    "            pairs = zip(agents_on_tile[:-1], agents_on_tile[1:])\n",
    "\n",
    "            for pair in pairs:\n",
    "                \n",
    "                self.conflict(pair[0], pair[1])\n",
    "\n",
    "        if len(agents_on_tile) == 1:\n",
    "            self.rewards[agents_on_tile[0]] += 5\n",
    "\n",
    "\n",
    "    def relocate_agent(self, agent):\n",
    "        # Relocate the agent to an adjacent position\n",
    "        agent_position = self.agent_positions[agent]\n",
    "\n",
    "        valid_position = False\n",
    "        step = 1\n",
    "        while not valid_position:\n",
    "\n",
    "            # Generate moves\n",
    "            possible_moves = np.array([[0, 1], [0, -1], [1, 0], [-1, 0]]) * step  # Right, Left, Down, Up\n",
    "\n",
    "            # Check if any of new positions are valid (within gridworld and not already occupied)\n",
    "            for move in possible_moves:\n",
    "                new_position = tuple(map(sum, zip(agent_position, move)))\n",
    "\n",
    "                if 0 <= new_position[0] < self.grid_size and 0 <= new_position[1] < self.grid_size:\n",
    "                    if np.isin((1,2), list(env.agent_positions.values())).any():\n",
    "\n",
    "                        valid_position = True\n",
    "                        self.agent_positions[agent] = new_position\n",
    "                        agent_position_map = np.zeros((self.grid_size, self.grid_size))\n",
    "                        agent_position_map[new_position] = 1\n",
    "                        self.agent_position_maps[agent] = agent_position_map\n",
    "\n",
    "            step += 1\n",
    "\n",
    "    def render(self):\n",
    "\n",
    "        fig = plt.figure(figsize=(5,5), frameon=False)\n",
    "\n",
    "        plt.title(\"Grid World\",size=13)\n",
    "        plt.xticks(np.arange(0,self.grid_size,1))\n",
    "        plt.yticks(np.arange(0,self.grid_size,1))\n",
    "\n",
    "        agent_position_map = sum(self.agent_position_maps.values())\n",
    "\n",
    "        plt.imshow(self.food_position_map, vmax = 2, cmap = 'Greens', alpha=0.4, extent=[0, 10, 0, 10])\n",
    "        plt.imshow(agent_position_map, vmax = 2, cmap = 'Reds', alpha=0.4, extent=[0, 10, 0, 10])\n",
    "\n",
    "        ax = plt.gca();\n",
    "        ax.grid()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "gym.register(\n",
    "    id='Hierarchy_Grid',\n",
    "    entry_point=Hierarchy_Grid,\n",
    "    kwargs={'grid_size': 10, 'num_agents': 10, 'max_iter': 1000}\n",
    ")\n",
    "\n",
    "env = gym.make('Hierarchy_Grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_shape, action_size):\n",
    "        self.state_shape = state_shape\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95  # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', name='Conv1', input_shape=self.state_shape))\n",
    "        model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', name='Conv2'))\n",
    "        model.add(MaxPool2D(name='MaxPool'))\n",
    "        model.add(Flatten(name='Flatten'))\n",
    "        model.add(Dense(128, activation='relu', name='Dense'))\n",
    "        model.add(Dense(self.action_size, activation='linear', name='output'))\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):  # action selection, epsilon-greedy.\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def update(self, state, action, reward, next_state):\n",
    "        target = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "        target_f = self.model.predict(state)\n",
    "        target_f[0][action] = target\n",
    "        self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma * np.amax(self.model.predict(next_state)[0]))\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-21T17:31:36.228778Z",
     "end_time": "2023-07-21T17:31:36.241117Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "id": "AI6-NSubtqn5",
    "ExecuteTime": {
     "start_time": "2023-07-21T11:31:12.853699Z",
     "end_time": "2023-07-21T11:31:34.164427Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: For this notebook to perform best, if possible, in the menu under `Runtime` -> `Change runtime type.`  select `GPU` \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "3\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "4\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "5\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "6\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "7\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "8\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "9\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "10\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "11\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "12\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "13\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "14\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "15\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "16\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "17\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "18\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "19\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "20\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "21\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "22\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "23\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "24\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "25\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "26\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "27\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "28\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "29\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "30\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "31\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "32\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "33\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "34\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "35\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "36\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "37\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "38\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "39\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "40\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "41\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:33<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[453], line 38\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;124;03m'''for agent in range(Np):  # the DQN should also be updated in each step\u001B[39;00m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;124;03m    players[p].remember(state[agent], action[agent], reward[agent], next_state, done)'''\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(Np):\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;66;03m# train the model in each step\u001B[39;00m\n\u001B[0;32m---> 38\u001B[0m     \u001B[43mplayers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mp\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m[\u001B[49m\u001B[43magent\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maction\u001B[49m\u001B[43m[\u001B[49m\u001B[43mp\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreward\u001B[49m\u001B[43m[\u001B[49m\u001B[43mp\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnext_state\u001B[49m\u001B[43m[\u001B[49m\u001B[43magent\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m     state \u001B[38;5;241m=\u001B[39m next_state\n\u001B[1;32m     41\u001B[0m timestep \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "Cell \u001B[0;32mIn[452], line 37\u001B[0m, in \u001B[0;36mDQNAgent.update\u001B[0;34m(self, state, action, reward, next_state)\u001B[0m\n\u001B[1;32m     35\u001B[0m target_f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mpredict(state)\n\u001B[1;32m     36\u001B[0m target_f[\u001B[38;5;241m0\u001B[39m][action] \u001B[38;5;241m=\u001B[39m target\n\u001B[0;32m---> 37\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_f\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:1682\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1672\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cluster_coordinator \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   1673\u001B[0m         tf\u001B[38;5;241m.\u001B[39mdistribute\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mcoordinator\u001B[38;5;241m.\u001B[39mClusterCoordinator(\n\u001B[1;32m   1674\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistribute_strategy\n\u001B[1;32m   1675\u001B[0m         )\n\u001B[1;32m   1676\u001B[0m     )\n\u001B[1;32m   1678\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistribute_strategy\u001B[38;5;241m.\u001B[39mscope(), training_utils\u001B[38;5;241m.\u001B[39mRespectCompiledTrainableState(  \u001B[38;5;66;03m# noqa: E501\u001B[39;00m\n\u001B[1;32m   1679\u001B[0m     \u001B[38;5;28mself\u001B[39m\n\u001B[1;32m   1680\u001B[0m ):\n\u001B[1;32m   1681\u001B[0m     \u001B[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001B[39;00m\n\u001B[0;32m-> 1682\u001B[0m     data_handler \u001B[38;5;241m=\u001B[39m \u001B[43mdata_adapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_data_handler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1683\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1684\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1685\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1686\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1687\u001B[0m \u001B[43m        \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1688\u001B[0m \u001B[43m        \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1689\u001B[0m \u001B[43m        \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1690\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1691\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1692\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1693\u001B[0m \u001B[43m        \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1694\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1695\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1696\u001B[0m \u001B[43m        \u001B[49m\u001B[43msteps_per_execution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_steps_per_execution\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1697\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1699\u001B[0m     \u001B[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001B[39;00m\n\u001B[1;32m   1700\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(callbacks, callbacks_module\u001B[38;5;241m.\u001B[39mCallbackList):\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/data_adapter.py:1678\u001B[0m, in \u001B[0;36mget_data_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1676\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1677\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _ClusterCoordinatorDataHandler(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m-> 1678\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataHandler\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/data_adapter.py:1304\u001B[0m, in \u001B[0;36mDataHandler.__init__\u001B[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001B[0m\n\u001B[1;32m   1301\u001B[0m strategy \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdistribute\u001B[38;5;241m.\u001B[39mget_strategy()\n\u001B[1;32m   1303\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m-> 1304\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_step_increment \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_steps_per_execution\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1305\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_insufficient_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1307\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_configure_dataset_and_inferred_steps(\n\u001B[1;32m   1308\u001B[0m     strategy, x, steps_per_epoch, class_weight, distribute\n\u001B[1;32m   1309\u001B[0m )\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:688\u001B[0m, in \u001B[0;36mBaseResourceVariable.numpy\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    686\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnumpy\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    687\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 688\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[1;32m    689\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[1;32m    690\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy() is only available when eager execution is enabled.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:818\u001B[0m, in \u001B[0;36mBaseResourceVariable.read_value\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    815\u001B[0m   value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read_variable_op()\n\u001B[1;32m    816\u001B[0m \u001B[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001B[39;00m\n\u001B[1;32m    817\u001B[0m \u001B[38;5;66;03m# specifies instead of the device where the variable is.\u001B[39;00m\n\u001B[0;32m--> 818\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marray_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43midentity\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1174\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[1;32m   1175\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1176\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdispatch_target\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[1;32m   1178\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[1;32m   1179\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[1;32m   1180\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:303\u001B[0m, in \u001B[0;36midentity\u001B[0;34m(input, name)\u001B[0m\n\u001B[1;32m    299\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m nest\u001B[38;5;241m.\u001B[39mmap_structure(identity, \u001B[38;5;28minput\u001B[39m, expand_composites\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    300\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraph\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    301\u001B[0m   \u001B[38;5;66;03m# Make sure we get an input with handle data attached from resource\u001B[39;00m\n\u001B[1;32m    302\u001B[0m   \u001B[38;5;66;03m# variables. Variables have correct handle data when graph building.\u001B[39;00m\n\u001B[0;32m--> 303\u001B[0m   \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    304\u001B[0m ret \u001B[38;5;241m=\u001B[39m gen_array_ops\u001B[38;5;241m.\u001B[39midentity(\u001B[38;5;28minput\u001B[39m, name\u001B[38;5;241m=\u001B[39mname)\n\u001B[1;32m    305\u001B[0m \u001B[38;5;66;03m# Propagate handle data for happier shape inference for resource variables.\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py:183\u001B[0m, in \u001B[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    181\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m Trace(trace_name, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtrace_kwargs):\n\u001B[1;32m    182\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 183\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1443\u001B[0m, in \u001B[0;36mconvert_to_tensor\u001B[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001B[0m\n\u001B[1;32m   1441\u001B[0m \u001B[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001B[39;00m\n\u001B[1;32m   1442\u001B[0m preferred_dtype \u001B[38;5;241m=\u001B[39m preferred_dtype \u001B[38;5;129;01mor\u001B[39;00m dtype_hint\n\u001B[0;32m-> 1443\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtensor_conversion_registry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1444\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_ref\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreferred_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccepted_result_types\u001B[49m\n\u001B[1;32m   1445\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:209\u001B[0m, in \u001B[0;36mconvert\u001B[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001B[0m\n\u001B[1;32m    207\u001B[0m overload \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(value, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__tf_tensor__\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    208\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m overload \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 209\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moverload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m#  pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    211\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m base_type, conversion_func \u001B[38;5;129;01min\u001B[39;00m get(\u001B[38;5;28mtype\u001B[39m(value)):\n\u001B[1;32m    212\u001B[0m   \u001B[38;5;66;03m# If dtype is None but preferred_dtype is not None, we try to\u001B[39;00m\n\u001B[1;32m    213\u001B[0m   \u001B[38;5;66;03m# cast to preferred_dtype first.\u001B[39;00m\n\u001B[1;32m    214\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1338\u001B[0m, in \u001B[0;36m_EagerTensorBase.__tf_tensor__\u001B[0;34m(self, dtype, name)\u001B[0m\n\u001B[1;32m   1332\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m   1333\u001B[0m         _add_error_prefix(\n\u001B[1;32m   1334\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttempting to capture an EagerTensor without \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1335\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbuilding a function.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1336\u001B[0m             name\u001B[38;5;241m=\u001B[39mname))\n\u001B[1;32m   1337\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m graph\u001B[38;5;241m.\u001B[39mcapture(\u001B[38;5;28mself\u001B[39m, name\u001B[38;5;241m=\u001B[39mname)\n\u001B[0;32m-> 1338\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m__tf_tensor__(dtype, name)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make('Hierarchy_Grid')\n",
    "n_actions = env.action_space.n\n",
    "state_shape = env.observation_space\n",
    "max_time = 100\n",
    "\n",
    "returns = {name: 0 for name in range(env.num_agents)}\n",
    "\n",
    "Np = env.num_agents\n",
    "players = []\n",
    "for i in range(Np):\n",
    "    players.append(DQNAgent((10, 10, 11), n_actions))\n",
    "\n",
    "Neps = 10\n",
    "\n",
    "# ---- model training/visualization loop\n",
    "DEVICE = set_device()\n",
    "for eps in tqdm(range(Neps)):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    timestep = 0\n",
    "    while timestep < max_time:\n",
    "        print(timestep)\n",
    "        action = []\n",
    "        # get actions of all agents\n",
    "        for p in range(Np):\n",
    "            action.append(players[p].act(state[p]))\n",
    "        next_state, reward, terminations, _, _ = env.step(action)  # we need reward to be a list of size Np\n",
    "\n",
    "        # Update returns\n",
    "        for agent in range(Np):\n",
    "            returns[agent] += reward[agent]\n",
    "\n",
    "        '''for agent in range(Np):  # the DQN should also be updated in each step\n",
    "            players[p].remember(state[agent], action[agent], reward[agent], next_state, done)'''\n",
    "\n",
    "        for p in range(Np):\n",
    "            # train the model in each step\n",
    "            players[p].update(state[agent], action[p], reward[p], next_state[agent])\n",
    "            state = next_state\n",
    "\n",
    "        timestep += 1\n",
    "\n",
    "    for n, model in enumerate(players):\n",
    "        model.save(f'Weights - Agent {n}')\n",
    "\n",
    "    # train the model by replay, leverages memory\n",
    "    '''batch_size = 32  # try a larger batch size for better stability and efficiency\n",
    "    for p in range(Np):\n",
    "        players[p].replay(batch_size)'''\n",
    "\n",
    "state, _ = env.reset()  # Reset the environment at the start of each episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0, 0.5, 'Total return')"
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(np.arange(10), list(returns.values()))\n",
    "plt.xlabel('Agent #')\n",
    "plt.ylabel('Total return')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-21T17:33:51.840324Z",
     "end_time": "2023-07-21T17:33:51.932082Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 500x500 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "action = []\n",
    "# get actions of all agents\n",
    "for p in range(Np):\n",
    "    action.append(players[p].act(state))\n",
    "\n",
    "state, reward, terminations, _, _ = env.step(action)\n",
    "\n",
    "env.render()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-21T17:34:09.993020Z",
     "end_time": "2023-07-21T17:34:10.043267Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
